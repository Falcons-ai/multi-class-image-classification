{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Tensorflow Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def count_subdirs_and_get_names(directory):\n",
    "    \"\"\"\n",
    "    Count the number of subdirectories in the given directory and assign their names to a list.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The path to the main directory.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of subdirectories.\n",
    "    list: A list containing the names of the subdirectories.\n",
    "    \"\"\"\n",
    "    # Get the list of subdirectories\n",
    "    subdirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    \n",
    "    # Count the number of subdirectories\n",
    "    num_subdirs = len(subdirs)\n",
    "    \n",
    "    return num_subdirs, subdirs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "# Best result 100\n",
    "\n",
    "batch_size = 256\n",
    "#Best result 256\n",
    "\n",
    "# Set image size for model training\n",
    "pic_size = 244\n",
    "\n",
    "#Set the data directory for training\n",
    "main_directory = './data_directory'\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_data_dir = main_directory+'/train/'\n",
    "validation_data_dir = main_directory+'/validation/'\n",
    "\n",
    "num_classes, lbl_classes = count_subdirs_and_get_names(train_data_dir)\n",
    "\n",
    "model_name = 'model/'+str(epochs)+'_tf_model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort classes alpha\n",
    "lbl_classes\n",
    "print(f\"pic size: {pic_size} X {pic_size}\")\n",
    "print(f'Batch Size: {batch_size}')\n",
    "print(f'Number of Epochs: {epochs}')\n",
    "print(f'Number of classes: {num_classes}')\n",
    "print(f'Class labels::{lbl_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Dataset balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "\n",
    "def count_images_in_subdirs(main_dir):\n",
    "    labels = []\n",
    "    counts = []\n",
    "\n",
    "    # Loop through each subdirectory in the main directory\n",
    "    for subdir in os.listdir(main_dir):\n",
    "        subdir_path = os.path.join(main_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Count the number of images in the subdirectory\n",
    "            image_files = natsorted(glob.glob(f\"{subdir_path}/*.jpg\"))\n",
    "            num_images = len(image_files)\n",
    "            labels.append(subdir)\n",
    "            counts.append(num_images)\n",
    "    \n",
    "    return labels, counts\n",
    "\n",
    "def generate_pie_chart(labels, counts, locf='Train'):\n",
    "    myexplode = [0.1] * len(labels)  # Adjust this list if you want specific slices to be exploded\n",
    "    \n",
    "    # Combine labels and counts for legend\n",
    "    legend_labels = [f\"{label} ({count})\" for label, count in zip(labels, counts)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12.8, 9.6))  # Make the chart 2x larger\n",
    "    ax.pie(counts, labels=labels, autopct='%1.1f%%',\n",
    "           colors=plt.cm.tab20.colors, explode=myexplode, shadow=True, startangle=90)\n",
    "    plt.legend(legend_labels, loc='upper right', title=locf + \" Image Count\")\n",
    "    plt.title(f\"{locf} - Image Distribution\")\n",
    "    plt.savefig('tf_'+locf+'_dataset_pie.png')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = count_images_in_subdirs(train_data_dir)\n",
    "generate_pie_chart(labels, counts, locf='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = count_images_in_subdirs(validation_data_dir)\n",
    "generate_pie_chart(labels, counts, locf='Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def display_random_images_from_subdirectories(root_dir, num_images_to_display=9):\n",
    "    all_images = []\n",
    "\n",
    "    # Walk through all directories and subdirectories\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        images = [os.path.join(subdir, f) for f in files if os.path.isfile(os.path.join(subdir, f)) and f.lower().endswith('.jpg')]\n",
    "        all_images.extend([(subdir, img) for img in images])\n",
    "\n",
    "    num_images = len(all_images)\n",
    "    print(f\"Total number of images found: {num_images}\")\n",
    "\n",
    "    if num_images < num_images_to_display:\n",
    "        print(\"Not enough images to display.\")\n",
    "        return\n",
    "\n",
    "    # Randomly select images from the accumulated list\n",
    "    random_images = random.sample(all_images, num_images_to_display)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    for i in range(num_images_to_display):\n",
    "        subdir, img_path = random_images[i]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        ax = axs[i // 3, i % 3]\n",
    "        if img.mode in ['L', 'P']:  # Check if the image is grayscale\n",
    "            ax.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.set_title(os.path.basename(subdir))\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "\n",
    "display_random_images_from_subdirectories(main_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(pic_size, pic_size),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    classes=lbl_classes)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(pic_size, pic_size),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    classes=lbl_classes)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(pic_size, pic_size, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Function to dynamically adjust the learning rate during model training\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr  \n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1)) \n",
    "\n",
    "# Create a learning rate scheduler callback\n",
    "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model with the learning rate scheduler callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[lr_scheduler_callback]  \n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Model Training Metrics Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Create a figure with subplots for accuracy and loss\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    axs[0].plot(history.history['accuracy'])\n",
    "    axs[0].plot(history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    axs[1].plot(history.history['loss'])\n",
    "    axs[1].plot(history.history['val_loss'])\n",
    "    axs[1].set_title('Model loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the combined figure\n",
    "    plt.savefig('tf_model_metrics.png')\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# After training the model using the code you provided,\n",
    "# you can call this function passing the history object as follows:\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Metrics in the Code\n",
    "\n",
    "The provided function visualizes the training history of a machine learning model, specifically focusing on accuracy and loss over the training epochs. Here’s a simplified explanation of each part:\n",
    "\n",
    "#### Function: `plot_training_history(history)`\n",
    "\n",
    "This function takes the `history` object returned by the `model.fit` method and plots the training and validation accuracy and loss values over the epochs.\n",
    "\n",
    "#### Plotting Accuracy\n",
    "\n",
    "1. **Training Accuracy**: The accuracy of the model on the training data for each epoch.\n",
    "2. **Validation Accuracy**: The accuracy of the model on the validation data for each epoch.\n",
    "3. **Plot**: Both training and validation accuracy are plotted on the same graph. This helps visualize how the model's accuracy changes over time and how well it performs on training versus unseen validation data.\n",
    "\n",
    "**Significance**:\n",
    "- **Training Accuracy**: Indicates how well the model is learning from the training data.\n",
    "- **Validation Accuracy**: Indicates how well the model generalizes to new, unseen data.\n",
    "- **Comparison**: High training accuracy but low validation accuracy may indicate overfitting.\n",
    "\n",
    "#### Plotting Loss\n",
    "\n",
    "1. **Training Loss**: The loss (error) of the model on the training data for each epoch.\n",
    "2. **Validation Loss**: The loss of the model on the validation data for each epoch.\n",
    "3. **Plot**: Both training and validation loss are plotted on the same graph. This helps visualize how the model’s loss changes over time and how well it minimizes error on training versus validation data.\n",
    "\n",
    "**Significance**:\n",
    "- **Training Loss**: Indicates how well the model is fitting the training data.\n",
    "- **Validation Loss**: Indicates how well the model is fitting the validation data.\n",
    "- **Comparison**: Lower training loss compared to validation loss may indicate overfitting, while high values for both may indicate underfitting.\n",
    "\n",
    "#### Usage\n",
    "\n",
    "To use this function, call it after training your model by passing the `history` object. This will generate and display the plots for accuracy and loss, helping diagnose issues like overfitting or underfitting. The plots are also saved as an image file named `model_metrics.png` for further reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the classes for the validation data\n",
    "validation_generator.reset()  # Ensure the generator is at the start\n",
    "predictions = model.predict(validation_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Create color maps: green for correct and red for incorrect predictions\n",
    "cmap_correct = plt.cm.Greens\n",
    "cmap_incorrect = plt.cm.Reds\n",
    "\n",
    "# Normalize the confusion matrix for color scaling\n",
    "norm_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot each cell\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        if i == j:\n",
    "            color = cmap_correct(norm_conf_matrix[i, j])\n",
    "        else:\n",
    "            color = cmap_incorrect(norm_conf_matrix[i, j])\n",
    "        ax.add_patch(plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=True, color=color, alpha=0.6))\n",
    "        ax.text(j, i, str(conf_matrix[i, j]), va='center', ha='center', color='black', fontsize=12)\n",
    "\n",
    "# Plot grid and labels\n",
    "ax.matshow(np.zeros_like(conf_matrix), cmap=plt.cm.Blues, alpha=0)  # Invisible grid overlay for structure\n",
    "ax.set_xticks(np.arange(len(class_labels)))\n",
    "ax.set_yticks(np.arange(len(class_labels)))\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "ax.set_yticklabels(class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Calculate scores for each label\n",
    "scores = [(class_labels[i], conf_matrix[i, i], conf_matrix[i].sum() - conf_matrix[i, i]) for i in range(len(class_labels))]\n",
    "\n",
    "# Sort scores by the number of correct predictions in descending order\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a legend with the sorted scores\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color=cmap_correct(0.6), lw=4, label=f'{label} Correct: {correct}, Incorrect: {incorrect}')\n",
    "    for label, correct, incorrect in scores\n",
    "]\n",
    "\n",
    "# Add the legend outside the plot\n",
    "ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1), title=\"Scores\")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('tf_confusion_matrix.png', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model. It provides a comprehensive summary of prediction results by comparing the actual and predicted classes. Here's a breakdown of what each element in the confusion matrix represents:\n",
    "\n",
    "#### Structure of the Confusion Matrix\n",
    "\n",
    "|                | Predicted Class 1 | Predicted Class 2 | ... | Predicted Class N |\n",
    "|----------------|-------------------|-------------------|-----|-------------------|\n",
    "| **Actual Class 1** | True Positive (TP)   | False Negative (FN) | ... | False Negative (FN) |\n",
    "| **Actual Class 2** | False Positive (FP)  | True Positive (TP)   | ... | False Negative (FN) |\n",
    "| ...            | ...               | ...               | ... | ...               |\n",
    "| **Actual Class N** | False Positive (FP)  | False Positive (FP)  | ... | True Positive (TP)   |\n",
    "\n",
    "#### Key Terms\n",
    "\n",
    "1. **True Positive (TP)**: The number of instances correctly predicted as the positive class.\n",
    "2. **True Negative (TN)**: The number of instances correctly predicted as the negative class.\n",
    "3. **False Positive (FP)**: The number of instances incorrectly predicted as the positive class (Type I error).\n",
    "4. **False Negative (FN)**: The number of instances incorrectly predicted as the negative class (Type II error).\n",
    "\n",
    "#### Metrics Derived from the Confusion Matrix\n",
    "\n",
    "- **Accuracy**: The overall correctness of the model, calculated as \\((TP + TN) / (TP + TN + FP + FN)\\).\n",
    "- **Precision**: The accuracy of positive predictions, calculated as \\(TP / (TP + FP)\\).\n",
    "- **Recall (Sensitivity)**: The ability of the model to find all the relevant cases (actual positives), calculated as \\(TP / (TP + FN)\\).\n",
    "- **F1 Score**: The harmonic mean of precision and recall, providing a single metric that balances both, calculated as \\(2 \\times (Precision \\times Recall) / (Precision + Recall)\\).\n",
    "\n",
    "#### Interpreting the Confusion Matrix\n",
    "\n",
    "- **Diagonal Elements (TP and TN)**: Represent the correct predictions. High values indicate good model performance.\n",
    "- **Off-Diagonal Elements (FP and FN)**: Represent the incorrect predictions. Low values are desirable.\n",
    "\n",
    "By analyzing the confusion matrix, you can identify specific areas where your model performs well and areas where it needs improvement. For example, a high number of false negatives might indicate that the model is missing instances of a particular class, while a high number of false positives might suggest that the model is incorrectly predicting instances as that class.\n",
    "\n",
    "Using the confusion matrix, you can fine-tune your model to improve its accuracy and reliability, especially for imbalanced datasets where certain classes may be underrepresented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img_path, model_name,lbl_classes,target_size=(pic_size, pic_size)):\n",
    "    \"\"\"\n",
    "    Classify a single image using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: Path to the image to be classified\n",
    "    - target_size: Size to which the image should be resized (default is (48, 48))\n",
    "\n",
    "    Returns:\n",
    "    - Predicted emotion label\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    # Load the trained model\n",
    "    model = load_model(model_name)\n",
    "\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=target_size, color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Scale pixel values to [0, 1]\n",
    "\n",
    "    # Make a prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    # Get the emotion label\n",
    "    emotion = lbl_classes[predicted_class]\n",
    "\n",
    "    # Load the image using OpenCV for displaying\n",
    "    img_cv = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Display the image and emotion prediction\n",
    "    plt.imshow(img_cv, cmap='gray')\n",
    "    plt.title(f'Prediction: {emotion}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return emotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through random images for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "\n",
    "def rand_images(test_path, model_name,lbl_classes):\n",
    "    \"\"\"\n",
    "    Lists all .jpg images in the specified directory and applies the classify_image function to each.\n",
    "    \n",
    "    Args:\n",
    "    directory (str): The directory to search for .jpg images.\n",
    "    model_name: The model to use for image classification.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    subdirs = [os.path.join(test_path, d) for d in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, d))]\n",
    "    all_images = []\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        images = [os.path.join(subdir, f) for f in os.listdir(subdir) if os.path.isfile(os.path.join(subdir, f)) and f.lower().endswith(('.jpg'))]\n",
    "        all_images.extend([(subdir, img) for img in images])\n",
    "\n",
    "    img = str(random.choice(all_images)[1])\n",
    "\n",
    "    classify_image(img, model_name,lbl_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_images(validation_data_dir, model_name,lbl_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_images(validation_data_dir, model_name,lbl_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_images(validation_data_dir, model_name,lbl_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
